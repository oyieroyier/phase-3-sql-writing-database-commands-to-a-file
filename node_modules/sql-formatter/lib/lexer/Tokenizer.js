"use strict";

function _typeof(obj) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && "function" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj; }, _typeof(obj); }

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports["default"] = void 0;

var _token = require("./token");

var regex = _interopRequireWildcard(require("./regexFactory"));

var _TokenizerEngine = _interopRequireDefault(require("./TokenizerEngine"));

var _regexUtil = require("./regexUtil");

var _utils = require("../utils");

var _NestedComment = require("./NestedComment");

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { "default": obj }; }

function _getRequireWildcardCache(nodeInterop) { if (typeof WeakMap !== "function") return null; var cacheBabelInterop = new WeakMap(); var cacheNodeInterop = new WeakMap(); return (_getRequireWildcardCache = function _getRequireWildcardCache(nodeInterop) { return nodeInterop ? cacheNodeInterop : cacheBabelInterop; })(nodeInterop); }

function _interopRequireWildcard(obj, nodeInterop) { if (!nodeInterop && obj && obj.__esModule) { return obj; } if (obj === null || _typeof(obj) !== "object" && typeof obj !== "function") { return { "default": obj }; } var cache = _getRequireWildcardCache(nodeInterop); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (key !== "default" && Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj["default"] = obj; if (cache) { cache.set(obj, newObj); } return newObj; }

function _toConsumableArray(arr) { return _arrayWithoutHoles(arr) || _iterableToArray(arr) || _unsupportedIterableToArray(arr) || _nonIterableSpread(); }

function _nonIterableSpread() { throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method."); }

function _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === "string") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === "Object" && o.constructor) n = o.constructor.name; if (n === "Map" || n === "Set") return Array.from(o); if (n === "Arguments" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }

function _iterableToArray(iter) { if (typeof Symbol !== "undefined" && iter[Symbol.iterator] != null || iter["@@iterator"] != null) return Array.from(iter); }

function _arrayWithoutHoles(arr) { if (Array.isArray(arr)) return _arrayLikeToArray(arr); }

function _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }

function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }

function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, "prototype", { writable: false }); return Constructor; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

var Tokenizer = /*#__PURE__*/function () {
  function Tokenizer(cfg) {
    _classCallCheck(this, Tokenizer);

    this.cfg = cfg;

    _defineProperty(this, "rulesBeforeParams", void 0);

    _defineProperty(this, "rulesAfterParams", void 0);

    this.rulesBeforeParams = this.buildRulesBeforeParams(cfg);
    this.rulesAfterParams = this.buildRulesAfterParams(cfg);
  }

  _createClass(Tokenizer, [{
    key: "tokenize",
    value: function tokenize(input, paramTypesOverrides) {
      var rules = [].concat(_toConsumableArray(this.rulesBeforeParams), _toConsumableArray(this.buildParamRules(this.cfg, paramTypesOverrides)), _toConsumableArray(this.rulesAfterParams));
      var tokens = new _TokenizerEngine["default"](rules).tokenize(input);
      return this.cfg.postProcess ? this.cfg.postProcess(tokens) : tokens;
    } // These rules can be cached as they only depend on
    // the Tokenizer config options specified for each SQL dialect

  }, {
    key: "buildRulesBeforeParams",
    value: function buildRulesBeforeParams(cfg) {
      var _cfg$lineCommentTypes, _cfg$reservedPhrases;

      return this.validRules([{
        type: _token.TokenType.BLOCK_COMMENT,
        regex: cfg.nestedBlockComments ? new _NestedComment.NestedComment() : new RegExp("(\\/\\*(?:(?![])[\\s\\S])*?\\*\\/)", "y")
      }, {
        type: _token.TokenType.LINE_COMMENT,
        regex: regex.lineComment((_cfg$lineCommentTypes = cfg.lineCommentTypes) !== null && _cfg$lineCommentTypes !== void 0 ? _cfg$lineCommentTypes : ['--'])
      }, {
        type: _token.TokenType.QUOTED_IDENTIFIER,
        regex: regex.string(cfg.identTypes)
      }, {
        type: _token.TokenType.NUMBER,
        regex: new RegExp("(?:0x[0-9A-Fa-f]+|0b[01]+|(?:\\x2D[\\t-\\r \\xA0\\u1680\\u2000-\\u200A\\u2028\\u2029\\u202F\\u205F\\u3000\\uFEFF]*)?[0-9]+(?:\\.[0-9]*)?(?:[Ee][\\+\\x2D]?[0-9]+(?:\\.[0-9]+)?)?)(?![0-9A-Z_a-z])", "y")
      }, // RESERVED_PHRASE is matched before all other keyword tokens
      // to e.g. prioritize matching "TIMESTAMP WITH TIME ZONE" phrase over "WITH" command.
      {
        type: _token.TokenType.RESERVED_PHRASE,
        regex: regex.reservedWord((_cfg$reservedPhrases = cfg.reservedPhrases) !== null && _cfg$reservedPhrases !== void 0 ? _cfg$reservedPhrases : [], cfg.identChars),
        text: toCanonical
      }, {
        type: _token.TokenType.CASE,
        regex: new RegExp("CA[S\\u017F]E\\b", "iy"),
        text: toCanonical
      }, {
        type: _token.TokenType.END,
        regex: new RegExp("END\\b", "iy"),
        text: toCanonical
      }, {
        type: _token.TokenType.BETWEEN,
        regex: new RegExp("BETWEEN\\b", "iy"),
        text: toCanonical
      }, {
        type: _token.TokenType.LIMIT,
        regex: cfg.reservedCommands.includes('LIMIT') ? new RegExp("LIMIT\\b", "iy") : undefined,
        text: toCanonical
      }, {
        type: _token.TokenType.RESERVED_COMMAND,
        regex: regex.reservedWord(cfg.reservedCommands, cfg.identChars),
        text: toCanonical
      }, {
        type: _token.TokenType.RESERVED_SELECT,
        regex: regex.reservedWord(cfg.reservedSelect, cfg.identChars),
        text: toCanonical
      }, {
        type: _token.TokenType.RESERVED_SET_OPERATION,
        regex: regex.reservedWord(cfg.reservedSetOperations, cfg.identChars),
        text: toCanonical
      }, {
        type: _token.TokenType.RESERVED_DEPENDENT_CLAUSE,
        regex: regex.reservedWord(cfg.reservedDependentClauses, cfg.identChars),
        text: toCanonical
      }, {
        type: _token.TokenType.RESERVED_JOIN,
        regex: regex.reservedWord(cfg.reservedJoins, cfg.identChars),
        text: toCanonical
      }, {
        type: _token.TokenType.AND,
        regex: new RegExp("AND\\b", "iy"),
        text: toCanonical
      }, {
        type: _token.TokenType.OR,
        regex: new RegExp("OR\\b", "iy"),
        text: toCanonical
      }, {
        type: _token.TokenType.XOR,
        regex: cfg.supportsXor ? new RegExp("XOR\\b", "iy") : undefined,
        text: toCanonical
      }, {
        type: _token.TokenType.RESERVED_FUNCTION_NAME,
        regex: regex.reservedWord(cfg.reservedFunctionNames, cfg.identChars),
        text: toCanonical
      }, {
        type: _token.TokenType.RESERVED_KEYWORD,
        regex: regex.reservedWord(cfg.reservedKeywords, cfg.identChars),
        text: toCanonical
      }]);
    } // These rules can also be cached as they only depend on
    // the Tokenizer config options specified for each SQL dialect

  }, {
    key: "buildRulesAfterParams",
    value: function buildRulesAfterParams(cfg) {
      var _cfg$operators;

      return this.validRules([{
        type: _token.TokenType.VARIABLE,
        regex: cfg.variableTypes ? regex.variable(cfg.variableTypes) : undefined
      }, {
        type: _token.TokenType.STRING,
        regex: regex.string(cfg.stringTypes)
      }, {
        type: _token.TokenType.IDENTIFIER,
        regex: regex.identifier(cfg.identChars)
      }, {
        type: _token.TokenType.DELIMITER,
        regex: new RegExp(";", "y")
      }, {
        type: _token.TokenType.COMMA,
        regex: new RegExp("[,]", "y")
      }, {
        type: _token.TokenType.OPEN_PAREN,
        regex: regex.parenthesis('open', cfg.extraParens)
      }, {
        type: _token.TokenType.CLOSE_PAREN,
        regex: regex.parenthesis('close', cfg.extraParens)
      }, {
        type: _token.TokenType.OPERATOR,
        regex: regex.operator([// standard operators
        '+', '-', '/', '>', '<', '=', '<>', '<=', '>=', '!='].concat(_toConsumableArray((_cfg$operators = cfg.operators) !== null && _cfg$operators !== void 0 ? _cfg$operators : [])))
      }, {
        type: _token.TokenType.ASTERISK,
        regex: new RegExp("\\*", "y")
      }, {
        type: _token.TokenType.DOT,
        regex: new RegExp("\\.", "y")
      }]);
    } // These rules can't be blindly cached as the paramTypesOverrides object
    // can differ on each invocation of the format() function.

  }, {
    key: "buildParamRules",
    value: function buildParamRules(cfg, paramTypesOverrides) {
      var _cfg$paramTypes, _cfg$paramTypes2, _cfg$paramTypes3, _cfg$paramTypes4;

      // Each dialect has its own default parameter types (if any),
      // but these can be overriden by the user of the library.
      var paramTypes = {
        named: (paramTypesOverrides === null || paramTypesOverrides === void 0 ? void 0 : paramTypesOverrides.named) || ((_cfg$paramTypes = cfg.paramTypes) === null || _cfg$paramTypes === void 0 ? void 0 : _cfg$paramTypes.named) || [],
        quoted: (paramTypesOverrides === null || paramTypesOverrides === void 0 ? void 0 : paramTypesOverrides.quoted) || ((_cfg$paramTypes2 = cfg.paramTypes) === null || _cfg$paramTypes2 === void 0 ? void 0 : _cfg$paramTypes2.quoted) || [],
        numbered: (paramTypesOverrides === null || paramTypesOverrides === void 0 ? void 0 : paramTypesOverrides.numbered) || ((_cfg$paramTypes3 = cfg.paramTypes) === null || _cfg$paramTypes3 === void 0 ? void 0 : _cfg$paramTypes3.numbered) || [],
        positional: typeof (paramTypesOverrides === null || paramTypesOverrides === void 0 ? void 0 : paramTypesOverrides.positional) === 'boolean' ? paramTypesOverrides.positional : (_cfg$paramTypes4 = cfg.paramTypes) === null || _cfg$paramTypes4 === void 0 ? void 0 : _cfg$paramTypes4.positional
      };
      return this.validRules([{
        type: _token.TokenType.NAMED_PARAMETER,
        regex: regex.parameter(paramTypes.named, regex.identifierPattern(cfg.paramChars || cfg.identChars)),
        key: function key(v) {
          return v.slice(1);
        }
      }, {
        type: _token.TokenType.QUOTED_PARAMETER,
        regex: regex.parameter(paramTypes.quoted, regex.stringPattern(cfg.identTypes)),
        key: function key(v) {
          return function (_ref) {
            var tokenKey = _ref.tokenKey,
                quoteChar = _ref.quoteChar;
            return tokenKey.replace(new RegExp((0, _regexUtil.escapeRegExp)('\\' + quoteChar), 'gu'), quoteChar);
          }({
            tokenKey: v.slice(2, -1),
            quoteChar: v.slice(-1)
          });
        }
      }, {
        type: _token.TokenType.NUMBERED_PARAMETER,
        regex: regex.parameter(paramTypes.numbered, '[0-9]+'),
        key: function key(v) {
          return v.slice(1);
        }
      }, {
        type: _token.TokenType.POSITIONAL_PARAMETER,
        regex: paramTypes.positional ? new RegExp("[?]", "y") : undefined
      }]);
    } // filters out rules for token types whose regex is undefined

  }, {
    key: "validRules",
    value: function validRules(rules) {
      return rules.filter(function (rule) {
        return Boolean(rule.regex);
      });
    }
  }]);

  return Tokenizer;
}();
/**
 * Converts keywords (and keyword sequences) to canonical form:
 * - in uppercase
 * - single spaces between words
 */


exports["default"] = Tokenizer;

var toCanonical = function toCanonical(v) {
  return (0, _utils.equalizeWhitespace)(v.toUpperCase());
};

module.exports = exports.default;
//# sourceMappingURL=Tokenizer.js.map