"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports["default"] = void 0;

var _LexerAdapter = _interopRequireDefault(require("./LexerAdapter"));

var _ast = require("./ast");

var _token = require("../lexer/token");

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { "default": obj }; }

function _toConsumableArray(arr) { return _arrayWithoutHoles(arr) || _iterableToArray(arr) || _unsupportedIterableToArray(arr) || _nonIterableSpread(); }

function _nonIterableSpread() { throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method."); }

function _iterableToArray(iter) { if (typeof Symbol !== "undefined" && iter[Symbol.iterator] != null || iter["@@iterator"] != null) return Array.from(iter); }

function _arrayWithoutHoles(arr) { if (Array.isArray(arr)) return _arrayLikeToArray(arr); }

function ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); enumerableOnly && (symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; })), keys.push.apply(keys, symbols); } return keys; }

function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = null != arguments[i] ? arguments[i] : {}; i % 2 ? ownKeys(Object(source), !0).forEach(function (key) { _defineProperty(target, key, source[key]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)) : ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

function _slicedToArray(arr, i) { return _arrayWithHoles(arr) || _iterableToArrayLimit(arr, i) || _unsupportedIterableToArray(arr, i) || _nonIterableRest(); }

function _nonIterableRest() { throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method."); }

function _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === "string") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === "Object" && o.constructor) n = o.constructor.name; if (n === "Map" || n === "Set") return Array.from(o); if (n === "Arguments" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }

function _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }

function _iterableToArrayLimit(arr, i) { var _i = arr == null ? null : typeof Symbol !== "undefined" && arr[Symbol.iterator] || arr["@@iterator"]; if (_i == null) return; var _arr = []; var _n = true; var _d = false; var _s, _e; try { for (_i = _i.call(arr); !(_n = (_s = _i.next()).done); _n = true) { _arr.push(_s.value); if (i && _arr.length === i) break; } } catch (err) { _d = true; _e = err; } finally { try { if (!_n && _i["return"] != null) _i["return"](); } finally { if (_d) throw _e; } } return _arr; }

function _arrayWithHoles(arr) { if (Array.isArray(arr)) return arr; }

// Generated automatically by nearley, version 2.20.1
// http://github.com/Hardmath123/nearley
// Bypasses TS6133. Allow declared but unused functions.
// @ts-ignore
function id(d) {
  return d[0];
}

// The lexer here is only to provide the has() method,
// that's used inside the generated grammar definition.
// A proper lexer gets passed to Nearley Parser constructor.
var lexer = new _LexerAdapter["default"](function (chunk) {
  return [];
}); // Used for unwrapping grammar rules like:
//
//   rule -> ( foo | bar | baz )
//
// which otherwise produce single element nested inside two arrays

var unwrap = function unwrap(_ref) {
  var _ref2 = _slicedToArray(_ref, 1),
      _ref2$ = _slicedToArray(_ref2[0], 1),
      el = _ref2$[0];

  return el;
};

var toKeywordNode = function toKeywordNode(token) {
  return {
    type: _ast.NodeType.keyword,
    tokenType: token.type,
    text: token.text,
    raw: token.raw
  };
};

var addLeadingComments = function addLeadingComments(node, comments) {
  return comments.length > 0 ? _objectSpread(_objectSpread({}, node), {}, {
    leadingComments: comments
  }) : node;
};

var addTrailingComments = function addTrailingComments(node, comments) {
  return comments.length > 0 ? _objectSpread(_objectSpread({}, node), {}, {
    trailingComments: comments
  }) : node;
};

;
;
;
;
var grammar = {
  Lexer: lexer,
  ParserRules: [{
    "name": "main$ebnf$1",
    "symbols": []
  }, {
    "name": "main$ebnf$1",
    "symbols": ["main$ebnf$1", "statement"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "main",
    "symbols": ["main$ebnf$1"],
    "postprocess": function postprocess(_ref3) {
      var _ref4 = _slicedToArray(_ref3, 1),
          statements = _ref4[0];

      var last = statements[statements.length - 1];

      if (last && !last.hasSemicolon) {
        // we have fully parsed the whole file
        // discard the last statement when it's empty
        return last.children.length > 0 ? statements : statements.slice(0, -1);
      } else {
        // parsing still in progress, do nothing
        return statements;
      }
    }
  }, {
    "name": "statement$subexpression$1",
    "symbols": [lexer.has("DELIMITER") ? {
      type: "DELIMITER"
    } : DELIMITER]
  }, {
    "name": "statement$subexpression$1",
    "symbols": [lexer.has("EOF") ? {
      type: "EOF"
    } : EOF]
  }, {
    "name": "statement",
    "symbols": ["expressions_or_clauses", "statement$subexpression$1"],
    "postprocess": function postprocess(_ref5) {
      var _ref6 = _slicedToArray(_ref5, 2),
          children = _ref6[0],
          _ref6$ = _slicedToArray(_ref6[1], 1),
          delimiter = _ref6$[0];

      return {
        type: _ast.NodeType.statement,
        children: children,
        hasSemicolon: delimiter.type === _token.TokenType.DELIMITER
      };
    }
  }, {
    "name": "expressions_or_clauses$ebnf$1",
    "symbols": []
  }, {
    "name": "expressions_or_clauses$ebnf$1",
    "symbols": ["expressions_or_clauses$ebnf$1", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "expressions_or_clauses$ebnf$2",
    "symbols": []
  }, {
    "name": "expressions_or_clauses$ebnf$2",
    "symbols": ["expressions_or_clauses$ebnf$2", "clause"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "expressions_or_clauses",
    "symbols": ["expressions_or_clauses$ebnf$1", "expressions_or_clauses$ebnf$2"],
    "postprocess": function postprocess(_ref7) {
      var _ref8 = _slicedToArray(_ref7, 2),
          expressions = _ref8[0],
          clauses = _ref8[1];

      return [].concat(_toConsumableArray(expressions), _toConsumableArray(clauses));
    }
  }, {
    "name": "clause$subexpression$1",
    "symbols": ["limit_clause"]
  }, {
    "name": "clause$subexpression$1",
    "symbols": ["select_clause"]
  }, {
    "name": "clause$subexpression$1",
    "symbols": ["other_clause"]
  }, {
    "name": "clause$subexpression$1",
    "symbols": ["set_operation"]
  }, {
    "name": "clause",
    "symbols": ["clause$subexpression$1"],
    "postprocess": unwrap
  }, {
    "name": "limit_clause$ebnf$1",
    "symbols": ["expression_with_comments"]
  }, {
    "name": "limit_clause$ebnf$1",
    "symbols": ["limit_clause$ebnf$1", "expression_with_comments"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "limit_clause$ebnf$2$subexpression$1$ebnf$1",
    "symbols": ["expression"]
  }, {
    "name": "limit_clause$ebnf$2$subexpression$1$ebnf$1",
    "symbols": ["limit_clause$ebnf$2$subexpression$1$ebnf$1", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "limit_clause$ebnf$2$subexpression$1",
    "symbols": [lexer.has("COMMA") ? {
      type: "COMMA"
    } : COMMA, "limit_clause$ebnf$2$subexpression$1$ebnf$1"]
  }, {
    "name": "limit_clause$ebnf$2",
    "symbols": ["limit_clause$ebnf$2$subexpression$1"],
    "postprocess": id
  }, {
    "name": "limit_clause$ebnf$2",
    "symbols": [],
    "postprocess": function postprocess() {
      return null;
    }
  }, {
    "name": "limit_clause",
    "symbols": [lexer.has("LIMIT") ? {
      type: "LIMIT"
    } : LIMIT, "_", "limit_clause$ebnf$1", "limit_clause$ebnf$2"],
    "postprocess": function postprocess(_ref9) {
      var _ref10 = _slicedToArray(_ref9, 4),
          limitToken = _ref10[0],
          _ = _ref10[1],
          exp1 = _ref10[2],
          optional = _ref10[3];

      if (optional) {
        var _optional = _slicedToArray(optional, 2),
            comma = _optional[0],
            exp2 = _optional[1];

        return {
          type: _ast.NodeType.limit_clause,
          name: addTrailingComments(toKeywordNode(limitToken), _),
          offset: exp1,
          count: exp2
        };
      } else {
        return {
          type: _ast.NodeType.limit_clause,
          name: addTrailingComments(toKeywordNode(limitToken), _),
          count: exp1
        };
      }
    }
  }, {
    "name": "select_clause$subexpression$1$ebnf$1",
    "symbols": []
  }, {
    "name": "select_clause$subexpression$1$ebnf$1",
    "symbols": ["select_clause$subexpression$1$ebnf$1", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "select_clause$subexpression$1",
    "symbols": ["all_columns_asterisk", "select_clause$subexpression$1$ebnf$1"]
  }, {
    "name": "select_clause$subexpression$1$ebnf$2",
    "symbols": []
  }, {
    "name": "select_clause$subexpression$1$ebnf$2",
    "symbols": ["select_clause$subexpression$1$ebnf$2", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "select_clause$subexpression$1",
    "symbols": ["asteriskless_expression", "select_clause$subexpression$1$ebnf$2"]
  }, {
    "name": "select_clause",
    "symbols": [lexer.has("RESERVED_SELECT") ? {
      type: "RESERVED_SELECT"
    } : RESERVED_SELECT, "select_clause$subexpression$1"],
    "postprocess": function postprocess(_ref11) {
      var _ref12 = _slicedToArray(_ref11, 2),
          nameToken = _ref12[0],
          _ref12$ = _slicedToArray(_ref12[1], 2),
          exp = _ref12$[0],
          expressions = _ref12$[1];

      return {
        type: _ast.NodeType.clause,
        name: toKeywordNode(nameToken),
        children: [exp].concat(_toConsumableArray(expressions))
      };
    }
  }, {
    "name": "select_clause",
    "symbols": [lexer.has("RESERVED_SELECT") ? {
      type: "RESERVED_SELECT"
    } : RESERVED_SELECT],
    "postprocess": function postprocess(_ref13) {
      var _ref14 = _slicedToArray(_ref13, 1),
          nameToken = _ref14[0];

      return {
        type: _ast.NodeType.clause,
        name: toKeywordNode(nameToken),
        children: []
      };
    }
  }, {
    "name": "all_columns_asterisk",
    "symbols": [lexer.has("ASTERISK") ? {
      type: "ASTERISK"
    } : ASTERISK],
    "postprocess": function postprocess() {
      return {
        type: _ast.NodeType.all_columns_asterisk
      };
    }
  }, {
    "name": "other_clause$ebnf$1",
    "symbols": []
  }, {
    "name": "other_clause$ebnf$1",
    "symbols": ["other_clause$ebnf$1", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "other_clause",
    "symbols": [lexer.has("RESERVED_COMMAND") ? {
      type: "RESERVED_COMMAND"
    } : RESERVED_COMMAND, "other_clause$ebnf$1"],
    "postprocess": function postprocess(_ref15) {
      var _ref16 = _slicedToArray(_ref15, 2),
          nameToken = _ref16[0],
          children = _ref16[1];

      return {
        type: _ast.NodeType.clause,
        name: toKeywordNode(nameToken),
        children: children
      };
    }
  }, {
    "name": "set_operation$ebnf$1",
    "symbols": []
  }, {
    "name": "set_operation$ebnf$1",
    "symbols": ["set_operation$ebnf$1", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "set_operation",
    "symbols": [lexer.has("RESERVED_SET_OPERATION") ? {
      type: "RESERVED_SET_OPERATION"
    } : RESERVED_SET_OPERATION, "set_operation$ebnf$1"],
    "postprocess": function postprocess(_ref17) {
      var _ref18 = _slicedToArray(_ref17, 2),
          nameToken = _ref18[0],
          children = _ref18[1];

      return {
        type: _ast.NodeType.set_operation,
        name: toKeywordNode(nameToken),
        children: children
      };
    }
  }, {
    "name": "expression_with_comments",
    "symbols": ["simple_expression", "_"],
    "postprocess": function postprocess(_ref19) {
      var _ref20 = _slicedToArray(_ref19, 2),
          expr = _ref20[0],
          _ = _ref20[1];

      return addTrailingComments(expr, _);
    }
  }, {
    "name": "expression$subexpression$1",
    "symbols": ["simple_expression"]
  }, {
    "name": "expression$subexpression$1",
    "symbols": ["between_predicate"]
  }, {
    "name": "expression$subexpression$1",
    "symbols": ["comma"]
  }, {
    "name": "expression$subexpression$1",
    "symbols": ["comment"]
  }, {
    "name": "expression",
    "symbols": ["expression$subexpression$1"],
    "postprocess": unwrap
  }, {
    "name": "asteriskless_expression$subexpression$1",
    "symbols": ["simple_expression_without_asterisk"]
  }, {
    "name": "asteriskless_expression$subexpression$1",
    "symbols": ["between_predicate"]
  }, {
    "name": "asteriskless_expression$subexpression$1",
    "symbols": ["comma"]
  }, {
    "name": "asteriskless_expression$subexpression$1",
    "symbols": ["comment"]
  }, {
    "name": "asteriskless_expression",
    "symbols": ["asteriskless_expression$subexpression$1"],
    "postprocess": unwrap
  }, {
    "name": "simple_expression$subexpression$1",
    "symbols": ["simple_expression_without_asterisk"]
  }, {
    "name": "simple_expression$subexpression$1",
    "symbols": ["asterisk"]
  }, {
    "name": "simple_expression",
    "symbols": ["simple_expression$subexpression$1"],
    "postprocess": unwrap
  }, {
    "name": "simple_expression_without_asterisk$subexpression$1",
    "symbols": ["array_subscript"]
  }, {
    "name": "simple_expression_without_asterisk$subexpression$1",
    "symbols": ["function_call"]
  }, {
    "name": "simple_expression_without_asterisk$subexpression$1",
    "symbols": ["property_access"]
  }, {
    "name": "simple_expression_without_asterisk$subexpression$1",
    "symbols": ["parenthesis"]
  }, {
    "name": "simple_expression_without_asterisk$subexpression$1",
    "symbols": ["curly_braces"]
  }, {
    "name": "simple_expression_without_asterisk$subexpression$1",
    "symbols": ["square_brackets"]
  }, {
    "name": "simple_expression_without_asterisk$subexpression$1",
    "symbols": ["operator"]
  }, {
    "name": "simple_expression_without_asterisk$subexpression$1",
    "symbols": ["identifier"]
  }, {
    "name": "simple_expression_without_asterisk$subexpression$1",
    "symbols": ["parameter"]
  }, {
    "name": "simple_expression_without_asterisk$subexpression$1",
    "symbols": ["literal"]
  }, {
    "name": "simple_expression_without_asterisk$subexpression$1",
    "symbols": ["keyword"]
  }, {
    "name": "simple_expression_without_asterisk",
    "symbols": ["simple_expression_without_asterisk$subexpression$1"],
    "postprocess": unwrap
  }, {
    "name": "array_subscript",
    "symbols": [lexer.has("ARRAY_IDENTIFIER") ? {
      type: "ARRAY_IDENTIFIER"
    } : ARRAY_IDENTIFIER, "_", "square_brackets"],
    "postprocess": function postprocess(_ref21) {
      var _ref22 = _slicedToArray(_ref21, 3),
          arrayToken = _ref22[0],
          _ = _ref22[1],
          brackets = _ref22[2];

      return {
        type: _ast.NodeType.array_subscript,
        array: addTrailingComments({
          type: _ast.NodeType.identifier,
          text: arrayToken.text
        }, _),
        parenthesis: brackets
      };
    }
  }, {
    "name": "array_subscript",
    "symbols": [lexer.has("ARRAY_KEYWORD") ? {
      type: "ARRAY_KEYWORD"
    } : ARRAY_KEYWORD, "_", "square_brackets"],
    "postprocess": function postprocess(_ref23) {
      var _ref24 = _slicedToArray(_ref23, 3),
          arrayToken = _ref24[0],
          _ = _ref24[1],
          brackets = _ref24[2];

      return {
        type: _ast.NodeType.array_subscript,
        array: addTrailingComments(toKeywordNode(arrayToken), _),
        parenthesis: brackets
      };
    }
  }, {
    "name": "function_call",
    "symbols": [lexer.has("RESERVED_FUNCTION_NAME") ? {
      type: "RESERVED_FUNCTION_NAME"
    } : RESERVED_FUNCTION_NAME, "_", "parenthesis"],
    "postprocess": function postprocess(_ref25) {
      var _ref26 = _slicedToArray(_ref25, 3),
          nameToken = _ref26[0],
          _ = _ref26[1],
          parens = _ref26[2];

      return {
        type: _ast.NodeType.function_call,
        name: addTrailingComments(toKeywordNode(nameToken), _),
        parenthesis: parens
      };
    }
  }, {
    "name": "parenthesis",
    "symbols": [{
      "literal": "("
    }, "expressions_or_clauses", {
      "literal": ")"
    }],
    "postprocess": function postprocess(_ref27) {
      var _ref28 = _slicedToArray(_ref27, 3),
          open = _ref28[0],
          children = _ref28[1],
          close = _ref28[2];

      return {
        type: _ast.NodeType.parenthesis,
        children: children,
        openParen: "(",
        closeParen: ")"
      };
    }
  }, {
    "name": "curly_braces$ebnf$1",
    "symbols": []
  }, {
    "name": "curly_braces$ebnf$1",
    "symbols": ["curly_braces$ebnf$1", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "curly_braces",
    "symbols": [{
      "literal": "{"
    }, "curly_braces$ebnf$1", {
      "literal": "}"
    }],
    "postprocess": function postprocess(_ref29) {
      var _ref30 = _slicedToArray(_ref29, 3),
          open = _ref30[0],
          children = _ref30[1],
          close = _ref30[2];

      return {
        type: _ast.NodeType.parenthesis,
        children: children,
        openParen: "{",
        closeParen: "}"
      };
    }
  }, {
    "name": "square_brackets$ebnf$1",
    "symbols": []
  }, {
    "name": "square_brackets$ebnf$1",
    "symbols": ["square_brackets$ebnf$1", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "square_brackets",
    "symbols": [{
      "literal": "["
    }, "square_brackets$ebnf$1", {
      "literal": "]"
    }],
    "postprocess": function postprocess(_ref31) {
      var _ref32 = _slicedToArray(_ref31, 3),
          open = _ref32[0],
          children = _ref32[1],
          close = _ref32[2];

      return {
        type: _ast.NodeType.parenthesis,
        children: children,
        openParen: "[",
        closeParen: "]"
      };
    }
  }, {
    "name": "property_access$subexpression$1",
    "symbols": ["identifier"]
  }, {
    "name": "property_access$subexpression$1",
    "symbols": ["array_subscript"]
  }, {
    "name": "property_access$subexpression$1",
    "symbols": ["all_columns_asterisk"]
  }, {
    "name": "property_access",
    "symbols": ["simple_expression", "_", lexer.has("DOT") ? {
      type: "DOT"
    } : DOT, "_", "property_access$subexpression$1"],
    "postprocess": // Allowing property to be <array_subscript> is currently a hack.
    // A better way would be to allow <property_access> on the left side of array_subscript,
    // but we currently can't do that because of another hack that requires
    // %ARRAY_IDENTIFIER on the left side of <array_subscript>.
    function postprocess(_ref33) {
      var _ref34 = _slicedToArray(_ref33, 5),
          object = _ref34[0],
          _1 = _ref34[1],
          dot = _ref34[2],
          _2 = _ref34[3],
          _ref34$ = _slicedToArray(_ref34[4], 1),
          property = _ref34$[0];

      return {
        type: _ast.NodeType.property_access,
        object: addTrailingComments(object, _1),
        property: addLeadingComments(property, _2)
      };
    }
  }, {
    "name": "between_predicate",
    "symbols": [lexer.has("BETWEEN") ? {
      type: "BETWEEN"
    } : BETWEEN, "_", "simple_expression", "_", lexer.has("AND") ? {
      type: "AND"
    } : AND, "_", "simple_expression"],
    "postprocess": function postprocess(_ref35) {
      var _ref36 = _slicedToArray(_ref35, 7),
          betweenToken = _ref36[0],
          _1 = _ref36[1],
          expr1 = _ref36[2],
          _2 = _ref36[3],
          andToken = _ref36[4],
          _3 = _ref36[5],
          expr2 = _ref36[6];

      return {
        type: _ast.NodeType.between_predicate,
        between: toKeywordNode(betweenToken),
        expr1: [addTrailingComments(addLeadingComments(expr1, _1), _2)],
        and: toKeywordNode(andToken),
        expr2: [addLeadingComments(expr2, _3)]
      };
    }
  }, {
    "name": "comma$subexpression$1",
    "symbols": [lexer.has("COMMA") ? {
      type: "COMMA"
    } : COMMA]
  }, {
    "name": "comma",
    "symbols": ["comma$subexpression$1"],
    "postprocess": function postprocess(_ref37) {
      var _ref38 = _slicedToArray(_ref37, 1),
          _ref38$ = _slicedToArray(_ref38[0], 1),
          token = _ref38$[0];

      return {
        type: _ast.NodeType.comma
      };
    }
  }, {
    "name": "asterisk$subexpression$1",
    "symbols": [lexer.has("ASTERISK") ? {
      type: "ASTERISK"
    } : ASTERISK]
  }, {
    "name": "asterisk",
    "symbols": ["asterisk$subexpression$1"],
    "postprocess": function postprocess(_ref39) {
      var _ref40 = _slicedToArray(_ref39, 1),
          _ref40$ = _slicedToArray(_ref40[0], 1),
          token = _ref40$[0];

      return {
        type: _ast.NodeType.operator,
        text: token.text
      };
    }
  }, {
    "name": "operator$subexpression$1",
    "symbols": [lexer.has("OPERATOR") ? {
      type: "OPERATOR"
    } : OPERATOR]
  }, {
    "name": "operator",
    "symbols": ["operator$subexpression$1"],
    "postprocess": function postprocess(_ref41) {
      var _ref42 = _slicedToArray(_ref41, 1),
          _ref42$ = _slicedToArray(_ref42[0], 1),
          token = _ref42$[0];

      return {
        type: _ast.NodeType.operator,
        text: token.text
      };
    }
  }, {
    "name": "identifier$subexpression$1",
    "symbols": [lexer.has("IDENTIFIER") ? {
      type: "IDENTIFIER"
    } : IDENTIFIER]
  }, {
    "name": "identifier$subexpression$1",
    "symbols": [lexer.has("QUOTED_IDENTIFIER") ? {
      type: "QUOTED_IDENTIFIER"
    } : QUOTED_IDENTIFIER]
  }, {
    "name": "identifier$subexpression$1",
    "symbols": [lexer.has("VARIABLE") ? {
      type: "VARIABLE"
    } : VARIABLE]
  }, {
    "name": "identifier",
    "symbols": ["identifier$subexpression$1"],
    "postprocess": function postprocess(_ref43) {
      var _ref44 = _slicedToArray(_ref43, 1),
          _ref44$ = _slicedToArray(_ref44[0], 1),
          token = _ref44$[0];

      return {
        type: _ast.NodeType.identifier,
        text: token.text
      };
    }
  }, {
    "name": "parameter$subexpression$1",
    "symbols": [lexer.has("NAMED_PARAMETER") ? {
      type: "NAMED_PARAMETER"
    } : NAMED_PARAMETER]
  }, {
    "name": "parameter$subexpression$1",
    "symbols": [lexer.has("QUOTED_PARAMETER") ? {
      type: "QUOTED_PARAMETER"
    } : QUOTED_PARAMETER]
  }, {
    "name": "parameter$subexpression$1",
    "symbols": [lexer.has("NUMBERED_PARAMETER") ? {
      type: "NUMBERED_PARAMETER"
    } : NUMBERED_PARAMETER]
  }, {
    "name": "parameter$subexpression$1",
    "symbols": [lexer.has("POSITIONAL_PARAMETER") ? {
      type: "POSITIONAL_PARAMETER"
    } : POSITIONAL_PARAMETER]
  }, {
    "name": "parameter",
    "symbols": ["parameter$subexpression$1"],
    "postprocess": function postprocess(_ref45) {
      var _ref46 = _slicedToArray(_ref45, 1),
          _ref46$ = _slicedToArray(_ref46[0], 1),
          token = _ref46$[0];

      return {
        type: _ast.NodeType.parameter,
        key: token.key,
        text: token.text
      };
    }
  }, {
    "name": "literal$subexpression$1",
    "symbols": [lexer.has("NUMBER") ? {
      type: "NUMBER"
    } : NUMBER]
  }, {
    "name": "literal$subexpression$1",
    "symbols": [lexer.has("STRING") ? {
      type: "STRING"
    } : STRING]
  }, {
    "name": "literal",
    "symbols": ["literal$subexpression$1"],
    "postprocess": function postprocess(_ref47) {
      var _ref48 = _slicedToArray(_ref47, 1),
          _ref48$ = _slicedToArray(_ref48[0], 1),
          token = _ref48$[0];

      return {
        type: _ast.NodeType.literal,
        text: token.text
      };
    }
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("RESERVED_KEYWORD") ? {
      type: "RESERVED_KEYWORD"
    } : RESERVED_KEYWORD]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("RESERVED_PHRASE") ? {
      type: "RESERVED_PHRASE"
    } : RESERVED_PHRASE]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("RESERVED_DEPENDENT_CLAUSE") ? {
      type: "RESERVED_DEPENDENT_CLAUSE"
    } : RESERVED_DEPENDENT_CLAUSE]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("RESERVED_JOIN") ? {
      type: "RESERVED_JOIN"
    } : RESERVED_JOIN]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("CASE") ? {
      type: "CASE"
    } : CASE]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("END") ? {
      type: "END"
    } : END]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("AND") ? {
      type: "AND"
    } : AND]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("OR") ? {
      type: "OR"
    } : OR]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("XOR") ? {
      type: "XOR"
    } : XOR]
  }, {
    "name": "keyword",
    "symbols": ["keyword$subexpression$1"],
    "postprocess": function postprocess(_ref49) {
      var _ref50 = _slicedToArray(_ref49, 1),
          _ref50$ = _slicedToArray(_ref50[0], 1),
          token = _ref50$[0];

      return toKeywordNode(token);
    }
  }, {
    "name": "_$ebnf$1",
    "symbols": []
  }, {
    "name": "_$ebnf$1",
    "symbols": ["_$ebnf$1", "comment"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "_",
    "symbols": ["_$ebnf$1"],
    "postprocess": function postprocess(_ref51) {
      var _ref52 = _slicedToArray(_ref51, 1),
          comments = _ref52[0];

      return comments;
    }
  }, {
    "name": "comment",
    "symbols": [lexer.has("LINE_COMMENT") ? {
      type: "LINE_COMMENT"
    } : LINE_COMMENT],
    "postprocess": function postprocess(_ref53) {
      var _ref54 = _slicedToArray(_ref53, 1),
          token = _ref54[0];

      return {
        type: _ast.NodeType.line_comment,
        text: token.text,
        precedingWhitespace: token.precedingWhitespace
      };
    }
  }, {
    "name": "comment",
    "symbols": [lexer.has("BLOCK_COMMENT") ? {
      type: "BLOCK_COMMENT"
    } : BLOCK_COMMENT],
    "postprocess": function postprocess(_ref55) {
      var _ref56 = _slicedToArray(_ref55, 1),
          token = _ref56[0];

      return {
        type: _ast.NodeType.block_comment,
        text: token.text
      };
    }
  }],
  ParserStart: "main"
};
var _default = grammar;
exports["default"] = _default;
module.exports = exports.default;
//# sourceMappingURL=grammar.js.map